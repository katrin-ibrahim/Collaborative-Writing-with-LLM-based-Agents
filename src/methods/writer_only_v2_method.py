# src/methods/writer_only_v2_method.py
"""
WriterOnlyV2 Method - Simplified single-agent method with deterministic workflows.

This method implements the hybrid architecture design using only WriterV2 agent
without any reviewer collaboration. Focuses on deterministic workflows and
clear content generation.
"""

import time

import logging

from src.collaborative.agents.writer_v2 import WriterV2
from src.collaborative.memory.memory import SharedMemory
from src.config.config_context import ConfigContext
from src.methods.base_method import BaseMethod
from src.utils.data import Article

logger = logging.getLogger(__name__)


class WriterOnlyV2Method(BaseMethod):
    """
    Single WriterV2 agent method with hybrid architecture.

    Features:
    - Hybrid architecture: Python orchestration + LLM content generation
    - Deterministic workflow for predictable execution
    - No collaboration complexity - pure writing focus
    - Clear error handling with no fallbacks
    - Minimal tool set for focused functionality

    Workflow:
    - WriterV2 executes iteration 0 workflow only:
      direct_search(topic) → generate_queries(top_chunk) → search_queries →
      create_outline(top_chunk) → write_all_sections(chunks)
    """

    def __init__(self):
        super().__init__()

    def run(self, topic: str) -> Article:
        """
        Run WriterV2-only method for article generation.

        Args:
            topic: Topic to write about

        Returns:
            Generated article with WriterV2 metadata
        """
        logger.info(f"Running WriterV2-only method for: {topic}")

        # Reset usage counters at start
        task_models = self._get_task_models_for_method()
        self._reset_all_client_usage(task_models)

        start_time = time.time()

        try:
            # Initialize shared memory (no collaboration features needed)
            memory = SharedMemory(
                topic=topic,
                tom_enabled=False,  # No collaboration, so no ToM needed
            )

            # Set memory instance for tools and agent to access
            ConfigContext.set_memory_instance(memory)

            # Initialize WriterV2 agent
            writer = WriterV2()

            # Initialize article state in memory
            seed_article = Article(
                title=topic,
                content=f"# {topic}\n\n",
                sections={},
                metadata={"method": "writer_only_v2"},
            )
            memory.update_article_state(seed_article)

            # WriterV2 executes iteration 0 workflow (research and write)
            logger.info(f"WriterV2 creating article for: {topic}")
            writer_start = time.time()

            try:
                writer.process()  # Will execute iteration 0 workflow
                writer_time = time.time() - writer_start
                logger.info("WriterV2 completed article creation")
            except Exception as e:
                logger.error(f"WriterV2 failed: {e}")
                raise RuntimeError(f"WriterV2 failed: {e}") from e

            # Get final article from memory
            final_draft = memory.get_current_draft()
            if not final_draft:
                raise RuntimeError("No final article generated by WriterV2")

            # Get current sections
            current_iteration = memory.get_iteration()
            sections = memory.get_sections_by_iteration(current_iteration)
            if not sections:
                sections = {}

            # Collect token usage statistics
            token_usage = self._collect_token_usage(task_models)

            # Build final article with comprehensive metadata
            total_time = time.time() - start_time

            final_article = Article(
                title=topic,
                content=final_draft,
                sections=sections,
                metadata={
                    # Standard metadata fields expected by output_manager
                    "generation_time": total_time,
                    "model": getattr(writer.api_client, "model_path", "unknown"),
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
                    # Method-specific metadata
                    "method": "writer_only_v2",
                    "agent_version": "v2",
                    "workflow_type": "hybrid_deterministic",
                    "total_iterations": 1,
                    "execution_time": total_time,
                    "detailed_timing": {
                        "total_time": total_time,
                        "writer_time": writer_time,
                        "overhead_time": total_time - writer_time,
                    },
                    "content_metrics": {
                        "character_count": len(final_draft),
                        "section_count": len(sections),
                        "word_count": len(final_draft.split()) if final_draft else 0,
                    },
                    "research_metrics": self._get_research_metrics(memory),
                    "workflow_steps": [
                        "direct_search",
                        "generate_queries",
                        "secondary_searches",
                        "create_outline",
                        "write_sections",
                    ],
                    "token_usage": token_usage,
                },
            )

            logger.info("WriterV2-only method completed successfully")
            logger.info(
                f"Final article: {len(final_article.content)} characters, {len(final_article.sections)} sections"
            )
            logger.info(
                f"Total time: {total_time:.2f}s, tokens: {token_usage['total_tokens']}"
            )

            return final_article

        except Exception as e:
            logger.error(f"WriterV2-only method failed: {e}", exc_info=True)
            raise RuntimeError(f"WriterOnlyV2Method failed: {e}") from e

    def _get_research_metrics(self, memory: SharedMemory) -> dict:
        """Get research metrics from memory."""
        try:
            stored_chunks = memory.get_stored_chunks()
            search_summaries = memory.get_search_summaries()

            return {
                "total_chunks": len(stored_chunks),
                "total_searches": len(search_summaries),
                "chunk_sources": list(
                    set(
                        chunk.source
                        for chunk in stored_chunks
                        if hasattr(chunk, "source")
                    )
                ),
                "average_chunk_length": (
                    sum(len(chunk.content) for chunk in stored_chunks)
                    / len(stored_chunks)
                    if stored_chunks
                    else 0
                ),
            }
        except Exception as e:
            logger.warning(f"Could not calculate research metrics: {e}")
            return {"error": str(e)}
