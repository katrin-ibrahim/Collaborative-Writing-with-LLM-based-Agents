# FILE: runners/runner_utils.py
from pathlib import Path

import logging
from typing import List

from baselines.llm_wrapper import OllamaLiteLLMWrapper
from config.model_config import ModelConfig
from utils.data_models import Article
from utils.ollama_client import OllamaClient

logger = logging.getLogger(__name__)


def get_model_wrapper(
    client: OllamaClient, config: ModelConfig, task: str
) -> OllamaLiteLLMWrapper:
    model = config.get_model_for_task(task)
    temp = config.get_temperature_for_task(task)
    max_tokens = config.get_token_limit_for_task(task)
    return OllamaLiteLLMWrapper(
        ollama_client=client, model=model, temperature=temp, max_tokens=max_tokens
    )


def build_direct_prompt(topic: str) -> str:
    return f"""Write a comprehensive, well-structured Wikipedia-style article about \"{topic}\".

Requirements:
1. Create a detailed article with multiple sections following Wikipedia structure
2. Use specific, descriptive section headings (e.g., "Background", "History", "Development", "Services", "Operations", "Technical specifications", "Impact", "Criticism", "Future plans")
3. Include an introduction, multiple main sections, and conclusion-style sections
4. Each section should have 2-3 paragraphs with specific details
5. Use clear markdown formatting with # for title and ## for sections
6. Write in an encyclopedic, factual style similar to Wikipedia
7. Aim for 1000-1500 words total
8. Include specific details, dates, numbers, and explanations
9. Avoid generic headings like "Overview" or "Introduction" - use specific descriptive titles

Format:
# {topic}

[Introduction paragraph with key facts]

## Background
[Historical context and background information]

## [Specific aspect like Development/History/Technology]
[Detailed content about this aspect]

## [Another specific aspect like Operations/Services/Impact]
[Content about this aspect]

## [Additional specific sections as relevant]
[Continue with domain-specific sections]

## [Future/Current status section]
[Information about current state and future plans]

Now write the article with specific, descriptive section headings:"""


def extract_storm_output(topic: str, storm_output_dir: str) -> str:
    topic_dir = Path(storm_output_dir) / topic.replace(" ", "_").replace("/", "_")
    output_files = [
        "storm_gen_article_polished.txt",
        "storm_gen_article.txt",
        "storm_gen_outline.txt",
    ]

    logger.debug(f"Looking for STORM output in: {topic_dir}")
    logger.debug(f"Directory exists: {topic_dir.exists()}")

    if topic_dir.exists():
        logger.debug(f"Directory contents: {list(topic_dir.iterdir())}")

    for filename in output_files:
        path = topic_dir / filename
        logger.debug(f"Checking file: {path}")
        logger.debug(f"File exists: {path.exists()}")

        if path.exists():
            try:
                content = path.read_text(encoding="utf-8")
                logger.debug(f"File content length: {len(content)}")
                logger.debug(f"Content preview: {content[:200]}...")

                if content.strip():
                    logger.info(f"Using STORM output from: {filename}")
                    return content
                else:
                    logger.warning(f"File {filename} is empty")
            except Exception as e:
                logger.warning(f"Could not read {path}: {e}")
        else:
            logger.debug(f"File does not exist: {path}")

    logger.error(f"No valid STORM output found for topic: {topic}")
    logger.error(f"Searched in directory: {topic_dir}")
    return f"# {topic}\n\nNo content generated by STORM."


def error_article(topic: str, error: Exception, method: str) -> Article:
    return Article(
        title=topic,
        content=f"# {topic}\n\nError: {str(error)}",
        sections={},
        metadata={"error": str(error), "method": method},
    )


def log_result(method: str, article: Article):
    if "error" in article.metadata:
        logger.warning(f"✗ {method} failed")
    else:
        wc = article.metadata.get("word_count", 0)
        logger.info(f"✓ {method} completed ({wc} words)")


def generate_search_queries(
    client, model_config, topic: str, num_queries: int = 3
) -> List[str]:
    """Generate diverse search queries for retrieval."""
    prompt = f"""Generate {num_queries} diverse search queries to research "{topic}".
Each query should explore a different key aspect of the topic.

Requirements:
- Make queries specific and focused
- Cover different aspects (history, current state, key facts, etc.)
- Keep queries concise and searchable
- One query per line, no numbering

Queries:"""

    wrapper = get_model_wrapper(client, model_config, "fast")
    response = wrapper(prompt)

    if hasattr(response, "choices") and response.choices:
        content = response.choices[0].message.content
    elif hasattr(response, "content"):
        content = response.content
    else:
        content = str(response)

    queries = [q.strip() for q in content.split("\n") if q.strip()]
    queries = [q for q in queries if len(q) > 5]

    if not queries:
        queries = [topic, f"{topic} history", f"{topic} overview"]

    return queries[:num_queries]


def retrieve_and_format_passages(retrieval_system, queries: List[str]) -> List[dict]:
    """Retrieve passages for queries and format consistently."""
    all_passages = []

    for query in queries:
        try:
            passages = retrieval_system.retrieve(query)
            for passage in passages:
                all_passages.append(
                    {
                        "content": passage.get("content", ""),
                        "title": passage.get("title", ""),
                        "relevance": passage.get("score", 0.5),
                    }
                )
        except Exception as e:
            logger.warning(f"Retrieval failed for query '{query}': {e}")

    return all_passages


def create_context_from_passages(passages: List[dict], max_passages: int = 5) -> str:
    """Create context string from retrieved passages."""
    if not passages:
        return ""

    # Sort by relevance and take top passages
    sorted_passages = sorted(
        passages, key=lambda x: x.get("relevance", 0), reverse=True
    )
    top_passages = sorted_passages[:max_passages]

    # Remove duplicates based on content similarity
    unique_passages = []
    for passage in top_passages:
        content = passage.get("content", "").strip()
        if content and not any(
            content in p.get("content", "") for p in unique_passages
        ):
            unique_passages.append(passage)

    # Format context
    context_parts = []
    for i, passage in enumerate(unique_passages, 1):
        title = passage.get("title", "Unknown")
        content = passage.get("content", "")
        if content:
            context_parts.append(f"[Source {i} - {title}]: {content}")

    context = "\n\n".join(context_parts)
    logger.debug(f"Created context with {len(unique_passages)} unique passages")

    return context


def generate_article_with_context(
    client, model_config, topic: str, context: str = ""
) -> str:
    """Generate article using retrieved context."""
    if context:
        prompt = f"""Write a comprehensive article about "{topic}" using the following retrieved information.

Retrieved Information:
{context}

Instructions:
1. Write a well-structured article with clear sections
2. Use the retrieved information to support your writing
3. Include specific facts and details from the sources
4. Start with "# {topic}" as the main title
5. Use markdown formatting for structure
6. Be comprehensive but concise

Article:"""
    else:
        prompt = f"""Write a comprehensive article about "{topic}".

Instructions:
1. Write a well-structured article with clear sections
2. Start with "# {topic}" as the main title
3. Use markdown formatting for structure
4. Be comprehensive but concise

Article:"""

    wrapper = get_model_wrapper(client, model_config, "writing")
    response = wrapper(prompt)

    if hasattr(response, "choices") and response.choices:
        content = response.choices[0].message.content
    elif hasattr(response, "content"):
        content = response.content
    else:
        content = str(response)

    # Ensure proper title format
    if not content.strip().startswith("#"):
        content = f"# {topic}\n\n{content}"

    return content
