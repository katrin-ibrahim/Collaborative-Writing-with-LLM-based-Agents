# Ollama configuration for local server
mode: 'ollama'
override_model: null
ollama_host: 'http://localhost:11434'

# Task-specific model assignments
outline_model: 'qwen3:4b'
writing_model: 'qwen3:4b'
critique_model: 'qwen3:4b'
polish_model: 'qwen3:4b'
default_model: 'qwen3:4b'

# Temperature settings per task
temperatures:
  fast: 0.5
  outline: 0.4
  writing: 0.6
  critique: 0.2
  polish: 0.3

# Token limits per task
token_limits:
  fast: 1200
  outline: 1200
  writing: 2500
  critique: 1200
  polish: 1200
