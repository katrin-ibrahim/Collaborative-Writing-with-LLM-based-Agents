# Ollama configuration for local server
mode: 'ollama'
override_model: null
ollama_host: 'http://localhost:11434'

# Task-specific model assignments
outline_model: 'qwen3:4b'
writing_model: 'gemma3:1b'
critique_model: 'gemma3:1b'
polish_model: 'qwen3:4b'
default_model: 'qwen3:4b'

# Temperature settings per task
temperatures:
  fast: 0.2
  outline: 0.2
  writing: 0.6
  critique: 0.2
  polish: 0.3

# Token limits per task
token_limits:
  fast: 5000
  outline: 1000
  writing: 8000
  critique: 1500
  polish: 1500
