# Model configuration for optimization
# This file configures which models to use for different tasks

mode: 'ollama' # Use "local" for local models or "ollama" for Ollama server

# Override model - if set, this model will be used for all tasks
override_model: 'qwen3:4b'

# Task-specific model assignments (will be overridden by override_model above)
outline_model: 'qwen3:4b'
writing_model: 'qwen3:4b'
critique_model: 'qwen3:4b'
polish_model: 'qwen3:4b'
default_model: 'qwen3:4b'

# Temperature settings per task (0.0 = deterministic, 1.0 = very creative)
temperatures:
  fast: 0.5
  outline: 0.4
  writing: 0.6
  critique: 0.2
  polish: 0.3

# Token limits per task
token_limits:
  fast: 1200
  outline: 1200
  writing: 2500
  critique: 1200
  polish: 1200

# Ollama model mapping (maps internal names to actual Ollama model names)
ollama_model_mapping:
  'qwen2.5:7b': 'qwen2.5:7b'
  'qwen2.5:14b': 'qwen2.5:14b'
  'qwen2.5:32b': 'qwen2.5:32b'
  'qwen3:4b': 'qwen3:4b'
  'qwen3:8b': 'qwen3:8b'
