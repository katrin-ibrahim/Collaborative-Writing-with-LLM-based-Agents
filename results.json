{
  "timestamp": "2025-07-14T16:57:49.735440",
  "configuration": {
    "methods": ["direct", "storm"],
    "num_topics": 100,
    "regenerated_from": "article_files",
    "source_directory": "/Users/katrin/Documents/Repos/Collaborative-Writing-with-LLM-based-Agents/results/ollama/run_20250709_104159/articles"
  },
  "results": {
    "2022_AFL_Grand_Final": {
      "direct": {
        "success": true,
        "word_count": 748,
        "metrics": {
          "rouge_1": 0.13967258794845003,
          "rouge_2": 0.03449477351916376,
          "rouge_l": 0.05886450714036921,
          "heading_soft_recall": 0.4069685535505414,
          "heading_entity_recall": 0.09375,
          "article_entity_recall": 0.1427038626609442
        }
      },
      "storm": {
        "success": true,
        "word_count": 1664,
        "metrics": {
          "rouge_1": 0.2601880877742947,
          "rouge_2": 0.05191637630662021,
          "rouge_l": 0.09996516893068617,
          "heading_soft_recall": 0.4138782601803541,
          "heading_entity_recall": 0.125,
          "article_entity_recall": 0.13948497854077252
        }
      }
    },
    "2022_Crimean_Bridge_explosion": {
      "direct": {
        "success": true,
        "word_count": 638,
        "metrics": {
          "rouge_1": 0.13070866141732285,
          "rouge_2": 0.05040957781978576,
          "rouge_l": 0.06425196850393701,
          "heading_soft_recall": 0.43961940010388695,
          "heading_entity_recall": 0.13636363636363635,
          "article_entity_recall": 0.13188798554652212
        }
      },
      "storm": {
        "success": true,
        "word_count": 1647,
        "metrics": {
          "rouge_1": 0.264251968503937,
          "rouge_2": 0.0816005040957782,
          "rouge_l": 0.10173228346456693,
          "heading_soft_recall": 0.41643763383229576,
          "heading_entity_recall": 0.09090909090909091,
          "article_entity_recall": 0.16440831074977416
        }
      }
    },
    "2022_Hungarian_parliamentary_election": {
      "direct": {
        "success": true,
        "word_count": 737,
        "metrics": {
          "rouge_1": 0.1616871704745167,
          "rouge_2": 0.04043600562587905,
          "rouge_l": 0.06502636203866433,
          "heading_soft_recall": 0.4686263409944681,
          "heading_entity_recall": 0.13333333333333333,
          "article_entity_recall": 0.15405651777575205
        }
      },
      "storm": {
        "success": true,
        "word_count": 1258,
        "metrics": {
          "rouge_1": 0.24710017574692442,
          "rouge_2": 0.06540084388185655,
          "rouge_l": 0.08857644991212654,
          "heading_soft_recall": 0.4661427071461311,
          "heading_entity_recall": 0.2,
          "article_entity_recall": 0.17137648131267091
        }
      }
    },
    "2022_Istanbul_bombing": {
      "direct": {
        "success": true,
        "word_count": 663,
        "metrics": {
          "rouge_1": 0.1250427058421592,
          "rouge_2": 0.032467532467532464,
          "rouge_l": 0.05534677143833276,
          "heading_soft_recall": 0.5725024123402203,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.11734693877551021
        }
      },
      "storm": {
        "success": true,
        "word_count": 2411,
        "metrics": {
          "rouge_1": 0.3262726340963444,
          "rouge_2": 0.06527682843472317,
          "rouge_l": 0.11991800478305432,
          "heading_soft_recall": 0.4244415939730756,
          "heading_entity_recall": 0.08333333333333333,
          "article_entity_recall": 0.16666666666666666
        }
      }
    },
    "2022_Luzon_earthquake": {
      "direct": {
        "success": true,
        "word_count": 719,
        "metrics": {
          "rouge_1": 0.15778853914447136,
          "rouge_2": 0.03552684699232943,
          "rouge_l": 0.06658595641646489,
          "heading_soft_recall": 0.40570472180843353,
          "heading_entity_recall": 0.23529411764705882,
          "article_entity_recall": 0.16310461192350956
        }
      },
      "storm": {
        "success": true,
        "word_count": 2007,
        "metrics": {
          "rouge_1": 0.3611783696529459,
          "rouge_2": 0.0904319741622931,
          "rouge_l": 0.12429378531073447,
          "heading_soft_recall": 0.3933052042355904,
          "heading_entity_recall": 0.17647058823529413,
          "article_entity_recall": 0.23059617547806524
        }
      }
    },
    "2022_New_York_City_Subway_attack": {
      "direct": {
        "success": true,
        "word_count": 722,
        "metrics": {
          "rouge_1": 0.15708052360174535,
          "rouge_2": 0.03888888888888889,
          "rouge_l": 0.0646568821896073,
          "heading_soft_recall": 0.4446568096225912,
          "heading_entity_recall": 0.1875,
          "article_entity_recall": 0.18259803921568626
        }
      },
      "storm": {
        "success": true,
        "word_count": 1359,
        "metrics": {
          "rouge_1": 0.29551765172550576,
          "rouge_2": 0.12063492063492064,
          "rouge_l": 0.1269337564458548,
          "heading_soft_recall": 0.5087690488858656,
          "heading_entity_recall": 0.125,
          "article_entity_recall": 0.25
        }
      }
    },
    "2022_Pakistan_floods": {
      "direct": {
        "success": true,
        "word_count": 618,
        "metrics": {
          "rouge_1": 0.11389593908629442,
          "rouge_2": 0.02316724849254205,
          "rouge_l": 0.044098984771573604,
          "heading_soft_recall": 0.4111407616963753,
          "heading_entity_recall": 0.045454545454545456,
          "article_entity_recall": 0.13111888111888112
        }
      },
      "storm": {
        "success": true,
        "word_count": 1454,
        "metrics": {
          "rouge_1": 0.23635786802030456,
          "rouge_2": 0.05172960964773088,
          "rouge_l": 0.07804568527918782,
          "heading_soft_recall": 0.3396124323973289,
          "heading_entity_recall": 0.13636363636363635,
          "article_entity_recall": 0.18706293706293706
        }
      }
    },
    "2022_UEFA_Champions_League_final": {
      "direct": {
        "success": true,
        "word_count": 887,
        "metrics": {
          "rouge_1": 0.19166666666666668,
          "rouge_2": 0.061827023271969435,
          "rouge_l": 0.07534722222222222,
          "heading_soft_recall": 0.5137654683169197,
          "heading_entity_recall": 0.14705882352941177,
          "article_entity_recall": 0.21861777150916784
        }
      },
      "storm": {
        "success": true,
        "word_count": 1992,
        "metrics": {
          "rouge_1": 0.3392361111111111,
          "rouge_2": 0.10281347690170198,
          "rouge_l": 0.12777777777777777,
          "heading_soft_recall": 0.5378054064862868,
          "heading_entity_recall": 0.14705882352941177,
          "article_entity_recall": 0.2397743300423131
        }
      }
    },
    "2022_United_States_Senate_election_in_Pennsylvania": {
      "direct": {
        "success": true,
        "word_count": 689,
        "metrics": {
          "rouge_1": 0.066655330726067,
          "rouge_2": 0.014965986394557823,
          "rouge_l": 0.03009692229212719,
          "heading_soft_recall": 0.48078787161244285,
          "heading_entity_recall": 0.1,
          "article_entity_recall": 0.08925081433224756
        }
      },
      "storm": {
        "success": true,
        "word_count": 1062,
        "metrics": {
          "rouge_1": 0.08723006291447033,
          "rouge_2": 0.015646258503401362,
          "rouge_l": 0.03434790001700391,
          "heading_soft_recall": 0.43913282867934966,
          "heading_entity_recall": 0.05,
          "article_entity_recall": 0.09381107491856677
        }
      }
    },
    "2022_Welsh_Open_(snooker)": {
      "direct": {
        "success": true,
        "word_count": 673,
        "metrics": {
          "rouge_1": 0.1419308357348703,
          "rouge_2": 0.05045045045045045,
          "rouge_l": 0.06736311239193084,
          "heading_soft_recall": 0.5164032074121329,
          "heading_entity_recall": 0.18518518518518517,
          "article_entity_recall": 0.1820689655172414
        }
      },
      "storm": {
        "success": true,
        "word_count": 1456,
        "metrics": {
          "rouge_1": 0.22586455331412103,
          "rouge_2": 0.04936936936936937,
          "rouge_l": 0.09546109510086455,
          "heading_soft_recall": 0.4667934821202205,
          "heading_entity_recall": 0.037037037037037035,
          "article_entity_recall": 0.18758620689655173
        }
      }
    },
    "2022_West_Java_earthquake": {
      "direct": {
        "success": true,
        "word_count": 755,
        "metrics": {
          "rouge_1": 0.12985199664898073,
          "rouge_2": 0.033798882681564245,
          "rouge_l": 0.054454063110862885,
          "heading_soft_recall": 0.5326233827150785,
          "heading_entity_recall": 0.19047619047619047,
          "article_entity_recall": 0.12759856630824373
        }
      },
      "storm": {
        "success": true,
        "word_count": 2576,
        "metrics": {
          "rouge_1": 0.2658475286232896,
          "rouge_2": 0.04357541899441341,
          "rouge_l": 0.09829656520524993,
          "heading_soft_recall": 0.5804157727039777,
          "heading_entity_recall": 0.23809523809523808,
          "article_entity_recall": 0.14695340501792115
        }
      }
    },
    "2022_Winter_Olympics_opening_ceremony": {
      "direct": {
        "success": true,
        "word_count": 784,
        "metrics": {
          "rouge_1": 0.14810849393290507,
          "rouge_2": 0.04426990360585505,
          "rouge_l": 0.06423982869379015,
          "heading_soft_recall": 0.36916993334889414,
          "heading_entity_recall": 0.017543859649122806,
          "article_entity_recall": 0.11969111969111969
        }
      },
      "storm": {
        "success": true,
        "word_count": 395,
        "metrics": {
          "rouge_1": 0.09172019985724482,
          "rouge_2": 0.04248482684755445,
          "rouge_l": 0.05460385438972163,
          "heading_soft_recall": 0.2258964566513896,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.08301158301158301
        }
      }
    },
    "2022_World_Figure_Skating_Championships": {
      "direct": {
        "success": true,
        "word_count": 701,
        "metrics": {
          "rouge_1": 0.22758152173913043,
          "rouge_2": 0.05098572399728076,
          "rouge_l": 0.08627717391304347,
          "heading_soft_recall": 0.3514468083779017,
          "heading_entity_recall": 0.038461538461538464,
          "article_entity_recall": 0.18459069020866772
        }
      },
      "storm": {
        "success": true,
        "word_count": 1899,
        "metrics": {
          "rouge_1": 0.35258152173913043,
          "rouge_2": 0.08633582596872875,
          "rouge_l": 0.140625,
          "heading_soft_recall": 0.5066055148839951,
          "heading_entity_recall": 0.11538461538461539,
          "article_entity_recall": 0.20545746388443017
        }
      }
    },
    "2023_Emilia-Romagna_floods": {
      "direct": {
        "success": true,
        "word_count": 662,
        "metrics": {
          "rouge_1": 0.0967741935483871,
          "rouge_2": 0.020336225596529284,
          "rouge_l": 0.04662510165356465,
          "heading_soft_recall": 0.40839870274066925,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.08634111818825195
        }
      },
      "storm": {
        "success": true,
        "word_count": 1626,
        "metrics": {
          "rouge_1": 0.20330712930333425,
          "rouge_2": 0.03850325379609545,
          "rouge_l": 0.07915424234209813,
          "heading_soft_recall": 0.36541050246783663,
          "heading_entity_recall": 0.05555555555555555,
          "article_entity_recall": 0.12455767869780608
        }
      }
    },
    "2023_Monterey_Park_shooting": {
      "direct": {
        "success": true,
        "word_count": 830,
        "metrics": {
          "rouge_1": 0.215598609041232,
          "rouge_2": 0.059145129224652086,
          "rouge_l": 0.08494783904619971,
          "heading_soft_recall": 0.5722178452544742,
          "heading_entity_recall": 0.17647058823529413,
          "article_entity_recall": 0.22527472527472528
        }
      },
      "storm": {
        "success": true,
        "word_count": 2224,
        "metrics": {
          "rouge_1": 0.3174366616989568,
          "rouge_2": 0.07157057654075547,
          "rouge_l": 0.13412816691505217,
          "heading_soft_recall": 0.43928611278533936,
          "heading_entity_recall": 0.11764705882352941,
          "article_entity_recall": 0.21703296703296704
        }
      }
    },
    "2023_Odisha_train_collision": {
      "direct": {
        "success": true,
        "word_count": 987,
        "metrics": {
          "rouge_1": 0.21017350157728706,
          "rouge_2": 0.046153846153846156,
          "rouge_l": 0.07610410094637224,
          "heading_soft_recall": 0.4389186389744282,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.19441460794844254
        }
      },
      "storm": {
        "success": true,
        "word_count": 2126,
        "metrics": {
          "rouge_1": 0.3939274447949527,
          "rouge_2": 0.11755424063116371,
          "rouge_l": 0.1447160883280757,
          "heading_soft_recall": 0.5604272447526455,
          "heading_entity_recall": 0.25,
          "article_entity_recall": 0.23523093447905477
        }
      }
    },
    "2023_SEA_Games": {
      "direct": {
        "success": true,
        "word_count": 874,
        "metrics": {
          "rouge_1": 0.13850174216027875,
          "rouge_2": 0.03659599186755736,
          "rouge_l": 0.06387921022067364,
          "heading_soft_recall": 0.3489347135736829,
          "heading_entity_recall": 0.03773584905660377,
          "article_entity_recall": 0.10907704042715484
        }
      },
      "storm": {
        "success": true,
        "word_count": 3104,
        "metrics": {
          "rouge_1": 0.3800813008130081,
          "rouge_2": 0.09352309032820215,
          "rouge_l": 0.1402439024390244,
          "heading_soft_recall": 0.4602582859141486,
          "heading_entity_recall": 0.09433962264150944,
          "article_entity_recall": 0.16704805491990846
        }
      }
    },
    "2023_Tour_de_France": {
      "direct": {
        "success": true,
        "word_count": 1009,
        "metrics": {
          "rouge_1": 0.16158730158730158,
          "rouge_2": 0.0387424579231502,
          "rouge_l": 0.07333333333333333,
          "heading_soft_recall": 0.36124683916568756,
          "heading_entity_recall": 0.043478260869565216,
          "article_entity_recall": 0.14335260115606938
        }
      },
      "storm": {
        "success": true,
        "word_count": 562,
        "metrics": {
          "rouge_1": 0.09428571428571429,
          "rouge_2": 0.024134645919339472,
          "rouge_l": 0.04698412698412698,
          "heading_soft_recall": 0.4034233093261719,
          "heading_entity_recall": 0.13043478260869565,
          "article_entity_recall": 0.09826589595375723
        }
      }
    },
    "2023_Wagner_Group_plane_crash": {
      "direct": {
        "success": true,
        "word_count": 932,
        "metrics": {
          "rouge_1": 0.17350684017350684,
          "rouge_2": 0.04472630173564753,
          "rouge_l": 0.07307307307307308,
          "heading_soft_recall": 0.5561684153296731,
          "heading_entity_recall": 0.25,
          "article_entity_recall": 0.13799126637554585
        }
      },
      "storm": {
        "success": true,
        "word_count": 1803,
        "metrics": {
          "rouge_1": 0.29496162829496164,
          "rouge_2": 0.0931241655540721,
          "rouge_l": 0.11945278611945279,
          "heading_soft_recall": 0.5527151552113619,
          "heading_entity_recall": 0.15,
          "article_entity_recall": 0.18602620087336244
        }
      }
    },
    "65th_Annual_Grammy_Awards": {
      "direct": {
        "success": true,
        "word_count": 800,
        "metrics": {
          "rouge_1": 0.32644628099173556,
          "rouge_2": 0.09410548086866598,
          "rouge_l": 0.14256198347107438,
          "heading_soft_recall": 0.35177816781732774,
          "heading_entity_recall": 0.0547945205479452,
          "article_entity_recall": 0.2805194805194805
        }
      },
      "storm": {
        "success": true,
        "word_count": 1517,
        "metrics": {
          "rouge_1": 0.33884297520661155,
          "rouge_2": 0.08583247156153051,
          "rouge_l": 0.15289256198347106,
          "heading_soft_recall": 0.3750100044740571,
          "heading_entity_recall": 0.0547945205479452,
          "article_entity_recall": 0.18961038961038962
        }
      }
    },
    "African_Greeks": {
      "direct": {
        "success": true,
        "word_count": 915,
        "metrics": {
          "rouge_1": 0.16017009213323885,
          "rouge_2": 0.02977667493796526,
          "rouge_l": 0.06413890857547838,
          "heading_soft_recall": 0.46212391380001516,
          "heading_entity_recall": 0.020833333333333332,
          "article_entity_recall": 0.17466802860061287
        }
      },
      "storm": {
        "success": true,
        "word_count": 752,
        "metrics": {
          "rouge_1": 0.1467044649184975,
          "rouge_2": 0.03580290677064871,
          "rouge_l": 0.06236711552090716,
          "heading_soft_recall": 0.40500178845489726,
          "heading_entity_recall": 0.041666666666666664,
          "article_entity_recall": 0.13585291113381
        }
      }
    },
    "Archie_Battersbee_case": {
      "direct": {
        "success": true,
        "word_count": 677,
        "metrics": {
          "rouge_1": 0.20809968847352026,
          "rouge_2": 0.038029925187032416,
          "rouge_l": 0.0778816199376947,
          "heading_soft_recall": 0.41504347920417783,
          "heading_entity_recall": 0.07692307692307693,
          "article_entity_recall": 0.18006430868167203
        }
      },
      "storm": {
        "success": true,
        "word_count": 2682,
        "metrics": {
          "rouge_1": 0.42866043613707167,
          "rouge_2": 0.09912718204488778,
          "rouge_l": 0.16573208722741434,
          "heading_soft_recall": 0.49002746790647506,
          "heading_entity_recall": 0.19230769230769232,
          "article_entity_recall": 0.26688102893890675
        }
      }
    },
    "Argentina_national_football_team": {
      "direct": {
        "success": true,
        "word_count": 763,
        "metrics": {
          "rouge_1": 0.11758691206543967,
          "rouge_2": 0.028125799028381488,
          "rouge_l": 0.05214723926380368,
          "heading_soft_recall": 0.4013554310798645,
          "heading_entity_recall": 0.04081632653061224,
          "article_entity_recall": 0.13457943925233645
        }
      },
      "storm": {
        "success": true,
        "word_count": 2013,
        "metrics": {
          "rouge_1": 0.3016359918200409,
          "rouge_2": 0.0933265149578113,
          "rouge_l": 0.1004601226993865,
          "heading_soft_recall": 0.5200544023513793,
          "heading_entity_recall": 0.22448979591836735,
          "article_entity_recall": 0.22990654205607478
        }
      }
    },
    "Armorial_of_Albania": {
      "direct": {
        "success": true,
        "word_count": 688,
        "metrics": {
          "rouge_1": 0.1970260223048327,
          "rouge_2": 0.03441860465116279,
          "rouge_l": 0.0845724907063197,
          "heading_soft_recall": 0.37298723061879474,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.11940298507462686
        }
      },
      "storm": {
        "success": true,
        "word_count": 2368,
        "metrics": {
          "rouge_1": 0.27695167286245354,
          "rouge_2": 0.12744186046511627,
          "rouge_l": 0.17936802973977695,
          "heading_soft_recall": 0.38346480826536816,
          "heading_entity_recall": 0.15,
          "article_entity_recall": 0.232409381663113
        }
      }
    },
    "Banjska_attack": {
      "direct": {
        "success": true,
        "word_count": 852,
        "metrics": {
          "rouge_1": 0.10428455941794665,
          "rouge_2": 0.018598382749326146,
          "rouge_l": 0.050121261115602264,
          "heading_soft_recall": 0.38345535298188527,
          "heading_entity_recall": 0.08,
          "article_entity_recall": 0.08995403808273145
        }
      },
      "storm": {
        "success": true,
        "word_count": 1984,
        "metrics": {
          "rouge_1": 0.2745890595526812,
          "rouge_2": 0.07924528301886792,
          "rouge_l": 0.10940447318782,
          "heading_soft_recall": 0.4631600856781006,
          "heading_entity_recall": 0.12,
          "article_entity_recall": 0.16414970453053185
        }
      }
    },
    "Barbie:_The_Album": {
      "direct": {
        "success": true,
        "word_count": 858,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 1764,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "Candidates_Tournament_2022": {
      "direct": {
        "success": true,
        "word_count": 821,
        "metrics": {
          "rouge_1": 0.2829386763812993,
          "rouge_2": 0.08748481166464156,
          "rouge_l": 0.11171827565270188,
          "heading_soft_recall": 0.32514396580782806,
          "heading_entity_recall": 0.05,
          "article_entity_recall": 0.25595238095238093
        }
      },
      "storm": {
        "success": true,
        "word_count": 1946,
        "metrics": {
          "rouge_1": 0.47783849423193686,
          "rouge_2": 0.1646415552855407,
          "rouge_l": 0.16636308439587127,
          "heading_soft_recall": 0.5064592822031542,
          "heading_entity_recall": 0.15,
          "article_entity_recall": 0.3888888888888889
        }
      }
    },
    "China_Eastern_Airlines_Flight_5735": {
      "direct": {
        "success": true,
        "word_count": 745,
        "metrics": {
          "rouge_1": 0.1730698865715331,
          "rouge_2": 0.05600292825768668,
          "rouge_l": 0.07720453713867545,
          "heading_soft_recall": 0.5230694189667702,
          "heading_entity_recall": 0.18181818181818182,
          "article_entity_recall": 0.18259935553168635
        }
      },
      "storm": {
        "success": true,
        "word_count": 494,
        "metrics": {
          "rouge_1": 0.10318331503841932,
          "rouge_2": 0.02342606149341142,
          "rouge_l": 0.04903036955726308,
          "heading_soft_recall": 0.31362716232736904,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.09237379162191192
        }
      }
    },
    "Chris_Sharma": {
      "direct": {
        "success": true,
        "word_count": 916,
        "metrics": {
          "rouge_1": 0.17076753580609622,
          "rouge_2": 0.034533431300514325,
          "rouge_l": 0.07051046639735586,
          "heading_soft_recall": 0.36897942516952753,
          "heading_entity_recall": 0.125,
          "article_entity_recall": 0.1437837837837838
        }
      },
      "storm": {
        "success": true,
        "word_count": 441,
        "metrics": {
          "rouge_1": 0.10796915167095116,
          "rouge_2": 0.03269654665686995,
          "rouge_l": 0.04921042967315461,
          "heading_soft_recall": 0.342036128975451,
          "heading_entity_recall": 0.075,
          "article_entity_recall": 0.09297297297297297
        }
      }
    },
    "Christian_Atsu": {
      "direct": {
        "success": true,
        "word_count": 703,
        "metrics": {
          "rouge_1": 0.16286644951140064,
          "rouge_2": 0.04114052953156823,
          "rouge_l": 0.07043973941368079,
          "heading_soft_recall": 0.5096254015670103,
          "heading_entity_recall": 0.30303030303030304,
          "article_entity_recall": 0.16084788029925187
        }
      },
      "storm": {
        "success": true,
        "word_count": 1858,
        "metrics": {
          "rouge_1": 0.3265472312703583,
          "rouge_2": 0.0769857433808554,
          "rouge_l": 0.12174267100977199,
          "heading_soft_recall": 0.4153102737139253,
          "heading_entity_recall": 0.21212121212121213,
          "article_entity_recall": 0.1970074812967581
        }
      }
    },
    "Cyclone_Batsirai": {
      "direct": {
        "success": true,
        "word_count": 1248,
        "metrics": {
          "rouge_1": 0.2144790257104195,
          "rouge_2": 0.046023688663282575,
          "rouge_l": 0.08051420838971583,
          "heading_soft_recall": 0.4359736078315311,
          "heading_entity_recall": 0.25,
          "article_entity_recall": 0.2808683853459973
        }
      },
      "storm": {
        "success": true,
        "word_count": 1414,
        "metrics": {
          "rouge_1": 0.21887686062246278,
          "rouge_2": 0.05752961082910321,
          "rouge_l": 0.08389715832205684,
          "heading_soft_recall": 0.48743801150057053,
          "heading_entity_recall": 0.25,
          "article_entity_recall": 0.2198100407055631
        }
      }
    },
    "Cyclone_Mocha": {
      "direct": {
        "success": true,
        "word_count": 807,
        "metrics": {
          "rouge_1": 0.15459882583170254,
          "rouge_2": 0.04274061990212072,
          "rouge_l": 0.06131767775603392,
          "heading_soft_recall": 0.3683060814033855,
          "heading_entity_recall": 0.06666666666666667,
          "article_entity_recall": 0.21501272264631044
        }
      },
      "storm": {
        "success": true,
        "word_count": 472,
        "metrics": {
          "rouge_1": 0.07566862361382909,
          "rouge_2": 0.01794453507340946,
          "rouge_l": 0.03946510110893672,
          "heading_soft_recall": 0.2559027238325639,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0737913486005089
        }
      }
    },
    "Dancing_with_the_Stars_(American_season_31)": {
      "direct": {
        "success": true,
        "word_count": 931,
        "metrics": {
          "rouge_1": 0.2563767168083715,
          "rouge_2": 0.049738219895287955,
          "rouge_l": 0.09287115761935906,
          "heading_soft_recall": 0.37703808810975814,
          "heading_entity_recall": 0.021739130434782608,
          "article_entity_recall": 0.26597938144329897
        }
      },
      "storm": {
        "success": true,
        "word_count": 2102,
        "metrics": {
          "rouge_1": 0.29823413996075865,
          "rouge_2": 0.05301047120418848,
          "rouge_l": 0.12949640287769784,
          "heading_soft_recall": 0.37641607887215084,
          "heading_entity_recall": 0.06521739130434782,
          "article_entity_recall": 0.2
        }
      }
    },
    "Darya_Dugina": {
      "direct": {
        "success": true,
        "word_count": 833,
        "metrics": {
          "rouge_1": 0.13843295137813563,
          "rouge_2": 0.02664188351920694,
          "rouge_l": 0.05667389284608238,
          "heading_soft_recall": 0.3826576888561249,
          "heading_entity_recall": 0.06521739130434782,
          "article_entity_recall": 0.11698717948717949
        }
      },
      "storm": {
        "success": true,
        "word_count": 468,
        "metrics": {
          "rouge_1": 0.06844224218024156,
          "rouge_2": 0.009603469640644362,
          "rouge_l": 0.035305048002477545,
          "heading_soft_recall": 0.26550875504811605,
          "heading_entity_recall": 0.043478260869565216,
          "article_entity_recall": 0.04887820512820513
        }
      }
    },
    "Death_and_funeral_of_Pope_Benedict_XVI": {
      "direct": {
        "success": true,
        "word_count": 740,
        "metrics": {
          "rouge_1": 0.17261904761904762,
          "rouge_2": 0.05240174672489083,
          "rouge_l": 0.07063492063492063,
          "heading_soft_recall": 0.559441996117433,
          "heading_entity_recall": 0.2222222222222222,
          "article_entity_recall": 0.12702702702702703
        }
      },
      "storm": {
        "success": true,
        "word_count": 1068,
        "metrics": {
          "rouge_1": 0.2,
          "rouge_2": 0.06550218340611354,
          "rouge_l": 0.08015873015873017,
          "heading_soft_recall": 0.45611275484164554,
          "heading_entity_recall": 0.07407407407407407,
          "article_entity_recall": 0.10990990990990991
        }
      }
    },
    "Dumas_Malone": {
      "direct": {
        "success": true,
        "word_count": 1097,
        "metrics": {
          "rouge_1": 0.11787819253438114,
          "rouge_2": 0.0075335735342286275,
          "rouge_l": 0.05926653569089718,
          "heading_soft_recall": 0.31894975155591965,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.09748743718592964
        }
      },
      "storm": {
        "success": true,
        "word_count": 1119,
        "metrics": {
          "rouge_1": 0.2295350360183366,
          "rouge_2": 0.07861120209629872,
          "rouge_l": 0.09430255402750491,
          "heading_soft_recall": 0.4341362863779068,
          "heading_entity_recall": 0.0967741935483871,
          "article_entity_recall": 0.15979899497487438
        }
      }
    },
    "E.A.T._(TV_program)": {
      "direct": {
        "success": true,
        "word_count": 1059,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 443,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "Edwards_Vacuum": {
      "direct": {
        "success": true,
        "word_count": 897,
        "metrics": {
          "rouge_1": 0.19708619991906112,
          "rouge_2": 0.038866396761133605,
          "rouge_l": 0.0764872521246459,
          "heading_soft_recall": 0.30107720429077744,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.15142276422764228
        }
      },
      "storm": {
        "success": true,
        "word_count": 1330,
        "metrics": {
          "rouge_1": 0.2727640631323351,
          "rouge_2": 0.06720647773279352,
          "rouge_l": 0.09591258599757184,
          "heading_soft_recall": 0.31832699570804834,
          "heading_entity_recall": 0.05714285714285714,
          "article_entity_recall": 0.16463414634146342
        }
      }
    },
    "Eukaryote": {
      "direct": {
        "success": true,
        "word_count": 930,
        "metrics": {
          "rouge_1": 0.17977893368010403,
          "rouge_2": 0.045203252032520326,
          "rouge_l": 0.06631989596879063,
          "heading_soft_recall": 0.5168080870062113,
          "heading_entity_recall": 0.06666666666666667,
          "article_entity_recall": 0.20041972717733472
        }
      },
      "storm": {
        "success": true,
        "word_count": 2440,
        "metrics": {
          "rouge_1": 0.34265279583875163,
          "rouge_2": 0.06991869918699187,
          "rouge_l": 0.11215864759427828,
          "heading_soft_recall": 0.5346780102699995,
          "heading_entity_recall": 0.1,
          "article_entity_recall": 0.2518363064008394
        }
      }
    },
    "Eurovision_Song_Contest_2024": {
      "direct": {
        "success": true,
        "word_count": 663,
        "metrics": {
          "rouge_1": 0.1344232515894641,
          "rouge_2": 0.03044070876874148,
          "rouge_l": 0.06085376930063579,
          "heading_soft_recall": 0.32372444548777174,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.103125
        }
      },
      "storm": {
        "success": true,
        "word_count": 2026,
        "metrics": {
          "rouge_1": 0.29427792915531337,
          "rouge_2": 0.056338028169014086,
          "rouge_l": 0.10899182561307902,
          "heading_soft_recall": 0.4333240155662809,
          "heading_entity_recall": 0.2,
          "article_entity_recall": 0.16979166666666667
        }
      }
    },
    "Fantastic_Beasts:_The_Secrets_of_Dumbledore": {
      "direct": {
        "success": true,
        "word_count": 846,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 2486,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "Febrile_seizure": {
      "direct": {
        "success": true,
        "word_count": 823,
        "metrics": {
          "rouge_1": 0.2807109252483011,
          "rouge_2": 0.0899581589958159,
          "rouge_l": 0.09461578672242552,
          "heading_soft_recall": 0.46890692710876464,
          "heading_entity_recall": 0.3333333333333333,
          "article_entity_recall": 0.3042016806722689
        }
      },
      "storm": {
        "success": true,
        "word_count": 2292,
        "metrics": {
          "rouge_1": 0.5608991113434396,
          "rouge_2": 0.19089958158995815,
          "rouge_l": 0.1651855723993727,
          "heading_soft_recall": 0.688336318731308,
          "heading_entity_recall": 0.4166666666666667,
          "article_entity_recall": 0.4218487394957983
        }
      }
    },
    "Funeral_for_Yesterday": {
      "direct": {
        "success": true,
        "word_count": 787,
        "metrics": {
          "rouge_1": 0.09643916913946587,
          "rouge_2": 0.01157613535173642,
          "rouge_l": 0.04599406528189911,
          "heading_soft_recall": 0.3835666589438915,
          "heading_entity_recall": 0.03571428571428571,
          "article_entity_recall": 0.09574468085106383
        }
      },
      "storm": {
        "success": true,
        "word_count": 2495,
        "metrics": {
          "rouge_1": 0.3002967359050445,
          "rouge_2": 0.05520926090828139,
          "rouge_l": 0.11008902077151335,
          "heading_soft_recall": 0.4392092414200306,
          "heading_entity_recall": 0.17857142857142858,
          "article_entity_recall": 0.1653771760154739
        }
      }
    },
    "Gehraiyaan": {
      "direct": {
        "success": true,
        "word_count": 741,
        "metrics": {
          "rouge_1": 0.17469586374695864,
          "rouge_2": 0.02872444011684518,
          "rouge_l": 0.07591240875912408,
          "heading_soft_recall": 0.6270501443317958,
          "heading_entity_recall": 0.42857142857142855,
          "article_entity_recall": 0.13590033975084936
        }
      },
      "storm": {
        "success": true,
        "word_count": 437,
        "metrics": {
          "rouge_1": 0.10997566909975669,
          "rouge_2": 0.02044790652385589,
          "rouge_l": 0.051094890510948905,
          "heading_soft_recall": 0.3526774453265326,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.07587768969422423
        }
      }
    },
    "George_Young_(swimmer)": {
      "direct": {
        "success": true,
        "word_count": 781,
        "metrics": {
          "rouge_1": 0.116382036685642,
          "rouge_2": 0.014552356849098386,
          "rouge_l": 0.05502846299810247,
          "heading_soft_recall": 0.423745123963607,
          "heading_entity_recall": 0.034482758620689655,
          "article_entity_recall": 0.10695742471443406
        }
      },
      "storm": {
        "success": true,
        "word_count": 1304,
        "metrics": {
          "rouge_1": 0.21062618595825428,
          "rouge_2": 0.04555520404935147,
          "rouge_l": 0.07969639468690702,
          "heading_soft_recall": 0.46130731780278056,
          "heading_entity_recall": 0.06896551724137931,
          "article_entity_recall": 0.17341640706126688
        }
      }
    },
    "Georgia_Guidestones": {
      "direct": {
        "success": true,
        "word_count": 759,
        "metrics": {
          "rouge_1": 0.17843051293292417,
          "rouge_2": 0.04868421052631579,
          "rouge_l": 0.0784743533537922,
          "heading_soft_recall": 0.4481790342501232,
          "heading_entity_recall": 0.041666666666666664,
          "article_entity_recall": 0.16493656286043828
        }
      },
      "storm": {
        "success": true,
        "word_count": 2094,
        "metrics": {
          "rouge_1": 0.34853134590092066,
          "rouge_2": 0.08157894736842106,
          "rouge_l": 0.13590530469092504,
          "heading_soft_recall": 0.4277477541140148,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.22606689734717417
        }
      }
    },
    "Good_News_International_Ministries": {
      "direct": {
        "success": true,
        "word_count": 1010,
        "metrics": {
          "rouge_1": 0.14415994387934059,
          "rouge_2": 0.015789473684210527,
          "rouge_l": 0.0634864959663276,
          "heading_soft_recall": 0.44303998351097107,
          "heading_entity_recall": 0.06666666666666667,
          "article_entity_recall": 0.11518324607329843
        }
      },
      "storm": {
        "success": true,
        "word_count": 242,
        "metrics": {
          "rouge_1": 0.04103823219922834,
          "rouge_2": 0.008070175438596491,
          "rouge_l": 0.022448263767099262,
          "heading_soft_recall": 0.2759763172694615,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.05130890052356021
        }
      }
    },
    "Green_Party_of_California": {
      "direct": {
        "success": true,
        "word_count": 1044,
        "metrics": {
          "rouge_1": 0.19045756746186937,
          "rouge_2": 0.04107981220657277,
          "rouge_l": 0.07195932733672272,
          "heading_soft_recall": 0.5189056396484375,
          "heading_entity_recall": 0.037037037037037035,
          "article_entity_recall": 0.22544283413848631
        }
      },
      "storm": {
        "success": true,
        "word_count": 597,
        "metrics": {
          "rouge_1": 0.12671098944075088,
          "rouge_2": 0.036384976525821594,
          "rouge_l": 0.06491982792334768,
          "heading_soft_recall": 0.34378401935100555,
          "heading_entity_recall": 0.07407407407407407,
          "article_entity_recall": 0.12077294685990338
        }
      }
    },
    "Herder_Memorial_Trophy": {
      "direct": {
        "success": true,
        "word_count": 802,
        "metrics": {
          "rouge_1": 0.1189922480620155,
          "rouge_2": 0.023264831329972858,
          "rouge_l": 0.06162790697674419,
          "heading_soft_recall": 0.3499585213139653,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.11932773109243698
        }
      },
      "storm": {
        "success": true,
        "word_count": 762,
        "metrics": {
          "rouge_1": 0.20775193798449612,
          "rouge_2": 0.097712291585886,
          "rouge_l": 0.10348837209302325,
          "heading_soft_recall": 0.41827039048075676,
          "heading_entity_recall": 0.2,
          "article_entity_recall": 0.15966386554621848
        }
      }
    },
    "Hessisches_Landesmuseum_Darmstadt": {
      "direct": {
        "success": true,
        "word_count": 1031,
        "metrics": {
          "rouge_1": 0.21861152141802068,
          "rouge_2": 0.03621581670362158,
          "rouge_l": 0.09453471196454949,
          "heading_soft_recall": 0.47128648843084064,
          "heading_entity_recall": 0.09090909090909091,
          "article_entity_recall": 0.1407528641571195
        }
      },
      "storm": {
        "success": true,
        "word_count": 641,
        "metrics": {
          "rouge_1": 0.16322008862629248,
          "rouge_2": 0.019955654101995565,
          "rouge_l": 0.0723781388478582,
          "heading_soft_recall": 0.4666006054197039,
          "heading_entity_recall": 0.09090909090909091,
          "article_entity_recall": 0.08019639934533551
        }
      }
    },
    "Hurricane_Hilary": {
      "direct": {
        "success": true,
        "word_count": 600,
        "metrics": {
          "rouge_1": 0.1137035819914558,
          "rouge_2": 0.028599605522682446,
          "rouge_l": 0.05192244495563589,
          "heading_soft_recall": 0.4322312942573002,
          "heading_entity_recall": 0.07692307692307693,
          "article_entity_recall": 0.1394335511982571
        }
      },
      "storm": {
        "success": true,
        "word_count": 1956,
        "metrics": {
          "rouge_1": 0.2182057180414065,
          "rouge_2": 0.03385930309007232,
          "rouge_l": 0.08478475188958265,
          "heading_soft_recall": 0.4011899594749723,
          "heading_entity_recall": 0.07692307692307693,
          "article_entity_recall": 0.14705882352941177
        }
      }
    },
    "Hurricane_Idalia": {
      "direct": {
        "success": true,
        "word_count": 681,
        "metrics": {
          "rouge_1": 0.10628415300546448,
          "rouge_2": 0.02896966384257994,
          "rouge_l": 0.046994535519125684,
          "heading_soft_recall": 0.3855689029608454,
          "heading_entity_recall": 0.047619047619047616,
          "article_entity_recall": 0.15483234714003946
        }
      },
      "storm": {
        "success": true,
        "word_count": 1380,
        "metrics": {
          "rouge_1": 0.21420765027322405,
          "rouge_2": 0.0743372506149221,
          "rouge_l": 0.09016393442622951,
          "heading_soft_recall": 0.3929604973111834,
          "heading_entity_recall": 0.09523809523809523,
          "article_entity_recall": 0.20907297830374755
        }
      }
    },
    "Illegal_operation_(euphemism)": {
      "direct": {
        "success": true,
        "word_count": 645,
        "metrics": {
          "rouge_1": 0.14225053078556263,
          "rouge_2": 0.01964949548592671,
          "rouge_l": 0.06634819532908705,
          "heading_soft_recall": 0.49347028271718457,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.08531994981179424
        }
      },
      "storm": {
        "success": true,
        "word_count": 2090,
        "metrics": {
          "rouge_1": 0.3487261146496815,
          "rouge_2": 0.06691449814126393,
          "rouge_l": 0.1332271762208068,
          "heading_soft_recall": 0.4144711318341168,
          "heading_entity_recall": 0.05555555555555555,
          "article_entity_recall": 0.20200752823086573
        }
      }
    },
    "Irene_Mawer": {
      "direct": {
        "success": true,
        "word_count": 792,
        "metrics": {
          "rouge_1": 0.1701534170153417,
          "rouge_2": 0.02744186046511628,
          "rouge_l": 0.07670850767085077,
          "heading_soft_recall": 0.42789595760405064,
          "heading_entity_recall": 0.15,
          "article_entity_recall": 0.13427109974424553
        }
      },
      "storm": {
        "success": true,
        "word_count": 933,
        "metrics": {
          "rouge_1": 0.18363551836355183,
          "rouge_2": 0.030232558139534883,
          "rouge_l": 0.08461180846118084,
          "heading_soft_recall": 0.33334115892648697,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.11125319693094629
        }
      }
    },
    "Jackass_Forever": {
      "direct": {
        "success": true,
        "word_count": 777,
        "metrics": {
          "rouge_1": 0.16236162361623616,
          "rouge_2": 0.052684563758389265,
          "rouge_l": 0.07279436430727944,
          "heading_soft_recall": 0.4703203352058635,
          "heading_entity_recall": 0.1,
          "article_entity_recall": 0.15485074626865672
        }
      },
      "storm": {
        "success": true,
        "word_count": 742,
        "metrics": {
          "rouge_1": 0.10466286481046629,
          "rouge_2": 0.01879194630872483,
          "rouge_l": 0.05266689030526669,
          "heading_soft_recall": 0.38651327175252576,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.06436567164179105
        }
      }
    },
    "James_Davis_(printer)": {
      "direct": {
        "success": true,
        "word_count": 1011,
        "metrics": {
          "rouge_1": 0.17252604166666666,
          "rouge_2": 0.030608922175187236,
          "rouge_l": 0.07552083333333333,
          "heading_soft_recall": 0.5353890545666218,
          "heading_entity_recall": 0.17391304347826086,
          "article_entity_recall": 0.15357561547479484
        }
      },
      "storm": {
        "success": true,
        "word_count": 2183,
        "metrics": {
          "rouge_1": 0.3818359375,
          "rouge_2": 0.1162487788993813,
          "rouge_l": 0.14095052083333334,
          "heading_soft_recall": 0.5526691600680351,
          "heading_entity_recall": 0.2608695652173913,
          "article_entity_recall": 0.2473622508792497
        }
      }
    },
    "Joe_Biden_classified_documents_incident": {
      "direct": {
        "success": true,
        "word_count": 823,
        "metrics": {
          "rouge_1": 0.1702571230020848,
          "rouge_2": 0.04831421619742788,
          "rouge_l": 0.06428075052119528,
          "heading_soft_recall": 0.42974997978461416,
          "heading_entity_recall": 0.07142857142857142,
          "article_entity_recall": 0.22588832487309646
        }
      },
      "storm": {
        "success": true,
        "word_count": 3622,
        "metrics": {
          "rouge_1": 0.45031271716469773,
          "rouge_2": 0.12964893986791798,
          "rouge_l": 0.16782487838776927,
          "heading_soft_recall": 0.49118877633621816,
          "heading_entity_recall": 0.17857142857142858,
          "article_entity_recall": 0.35913705583756345
        }
      }
    },
    "John_Harrison_Stonehouse": {
      "direct": {
        "success": true,
        "word_count": 743,
        "metrics": {
          "rouge_1": 0.17227523857358112,
          "rouge_2": 0.023115577889447236,
          "rouge_l": 0.08086388749372175,
          "heading_soft_recall": 0.40145973435470034,
          "heading_entity_recall": 0.21052631578947367,
          "article_entity_recall": 0.107095046854083
        }
      },
      "storm": {
        "success": true,
        "word_count": 1409,
        "metrics": {
          "rouge_1": 0.23656454043194375,
          "rouge_2": 0.03869346733668342,
          "rouge_l": 0.10547463586137619,
          "heading_soft_recall": 0.4896803093808038,
          "heading_entity_recall": 0.2631578947368421,
          "article_entity_recall": 0.11378848728246319
        }
      }
    },
    "July_2022_United_Kingdom_government_crisis": {
      "direct": {
        "success": true,
        "word_count": 710,
        "metrics": {
          "rouge_1": 0.1274564851207187,
          "rouge_2": 0.03847233923055322,
          "rouge_l": 0.05614823133071308,
          "heading_soft_recall": 0.4501025875409444,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.13297872340425532
        }
      },
      "storm": {
        "success": true,
        "word_count": 988,
        "metrics": {
          "rouge_1": 0.17883211678832117,
          "rouge_2": 0.06543105869137883,
          "rouge_l": 0.07327344188658057,
          "heading_soft_recall": 0.45702701144748265,
          "heading_entity_recall": 0.2777777777777778,
          "article_entity_recall": 0.16312056737588654
        }
      }
    },
    "Kenkoku_University": {
      "direct": {
        "success": true,
        "word_count": 587,
        "metrics": {
          "rouge_1": 0.124,
          "rouge_2": 0.024809923969587835,
          "rouge_l": 0.0552,
          "heading_soft_recall": 0.5678270123898983,
          "heading_entity_recall": 0.09090909090909091,
          "article_entity_recall": 0.10050761421319797
        }
      },
      "storm": {
        "success": true,
        "word_count": 2393,
        "metrics": {
          "rouge_1": 0.3524,
          "rouge_2": 0.07042817126850741,
          "rouge_l": 0.1396,
          "heading_soft_recall": 0.42891935631632805,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.15634517766497463
        }
      }
    },
    "Killing_of_Amir_Locke": {
      "direct": {
        "success": true,
        "word_count": 615,
        "metrics": {
          "rouge_1": 0.13644722324383965,
          "rouge_2": 0.03863134657836645,
          "rouge_l": 0.06583302684810592,
          "heading_soft_recall": 0.4488467504580816,
          "heading_entity_recall": 0.1,
          "article_entity_recall": 0.16610549943883277
        }
      },
      "storm": {
        "success": true,
        "word_count": 1602,
        "metrics": {
          "rouge_1": 0.35638102243471864,
          "rouge_2": 0.1526857983811626,
          "rouge_l": 0.13240161824200072,
          "heading_soft_recall": 0.5215154488881429,
          "heading_entity_recall": 0.26666666666666666,
          "article_entity_recall": 0.24130190796857465
        }
      }
    },
    "LK-99": {
      "direct": {
        "success": true,
        "word_count": 997,
        "metrics": {
          "rouge_1": 0.11617391304347827,
          "rouge_2": 0.011482254697286013,
          "rouge_l": 0.04765217391304348,
          "heading_soft_recall": 0.30775756149419714,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.12735849056603774
        }
      },
      "storm": {
        "success": true,
        "word_count": 560,
        "metrics": {
          "rouge_1": 0.10295652173913043,
          "rouge_2": 0.015309672929714684,
          "rouge_l": 0.04695652173913043,
          "heading_soft_recall": 0.36822784904922756,
          "heading_entity_recall": 0.05405405405405406,
          "article_entity_recall": 0.09905660377358491
        }
      }
    },
    "Lahaina,_Hawaii": {
      "direct": {
        "success": true,
        "word_count": 750,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 2582,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "Liga_1_(Indonesia)": {
      "direct": {
        "success": true,
        "word_count": 44,
        "metrics": {
          "rouge_1": 0.008115419296663661,
          "rouge_2": 0.0027063599458728013,
          "rouge_l": 0.008115419296663661,
          "heading_soft_recall": 0.28221192955970764,
          "heading_entity_recall": 0.021739130434782608,
          "article_entity_recall": 0.009615384615384616
        }
      },
      "storm": {
        "success": true,
        "word_count": 2297,
        "metrics": {
          "rouge_1": 0.3602344454463481,
          "rouge_2": 0.08254397834912043,
          "rouge_l": 0.1339044183949504,
          "heading_soft_recall": 0.4448768422007561,
          "heading_entity_recall": 0.15217391304347827,
          "article_entity_recall": 0.20072115384615385
        }
      }
    },
    "Luttra_Woman": {
      "direct": {
        "success": true,
        "word_count": 516,
        "metrics": {
          "rouge_1": 0.09260244811069718,
          "rouge_2": 0.005857294994675187,
          "rouge_l": 0.0494944119212347,
          "heading_soft_recall": 0.3756753295660019,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.06969205834683954
        }
      },
      "storm": {
        "success": true,
        "word_count": 2200,
        "metrics": {
          "rouge_1": 0.41883980840872803,
          "rouge_2": 0.10596379126730564,
          "rouge_l": 0.15274081958488558,
          "heading_soft_recall": 0.5873526126146317,
          "heading_entity_recall": 0.4444444444444444,
          "article_entity_recall": 0.2852512155591572
        }
      }
    },
    "Mass_and_Cass": {
      "direct": {
        "success": true,
        "word_count": 1010,
        "metrics": {
          "rouge_1": 0.11650853889943075,
          "rouge_2": 0.007972665148063782,
          "rouge_l": 0.05540796963946869,
          "heading_soft_recall": 0.3136366842424168,
          "heading_entity_recall": 0.01694915254237288,
          "article_entity_recall": 0.10855263157894737
        }
      },
      "storm": {
        "success": true,
        "word_count": 1528,
        "metrics": {
          "rouge_1": 0.19468690702087288,
          "rouge_2": 0.018982536066818528,
          "rouge_l": 0.08994307400379507,
          "heading_soft_recall": 0.252669310745071,
          "heading_entity_recall": 0.03389830508474576,
          "article_entity_recall": 0.09758771929824561
        }
      }
    },
    "Michelle_Yeoh": {
      "direct": {
        "success": true,
        "word_count": 930,
        "metrics": {
          "rouge_1": 0.15582791395697848,
          "rouge_2": 0.05128846634976232,
          "rouge_l": 0.06603301650825413,
          "heading_soft_recall": 0.5009749748490073,
          "heading_entity_recall": 0.06060606060606061,
          "article_entity_recall": 0.14560439560439561
        }
      },
      "storm": {
        "success": true,
        "word_count": 1993,
        "metrics": {
          "rouge_1": 0.24362181090545273,
          "rouge_2": 0.05654240680510383,
          "rouge_l": 0.08929464732366182,
          "heading_soft_recall": 0.6031126596710898,
          "heading_entity_recall": 0.18181818181818182,
          "article_entity_recall": 0.15796703296703296
        }
      }
    },
    "Minions:_The_Rise_of_Gru": {
      "direct": {
        "success": true,
        "word_count": 885,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 1259,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "Miss_Grand_International_2022": {
      "direct": {
        "success": true,
        "word_count": 745,
        "metrics": {
          "rouge_1": 0.1181651376146789,
          "rouge_2": 0.026064610866372982,
          "rouge_l": 0.052110091743119265,
          "heading_soft_recall": 0.3579629685948877,
          "heading_entity_recall": 0.027777777777777776,
          "article_entity_recall": 0.07734806629834254
        }
      },
      "storm": {
        "success": true,
        "word_count": 529,
        "metrics": {
          "rouge_1": 0.0891743119266055,
          "rouge_2": 0.02459618208516887,
          "rouge_l": 0.04110091743119266,
          "heading_soft_recall": 0.25905369134510264,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.055248618784530384
        }
      }
    },
    "Miss_Universe_2022": {
      "direct": {
        "success": true,
        "word_count": 878,
        "metrics": {
          "rouge_1": 0.19738988580750408,
          "rouge_2": 0.046789989118607184,
          "rouge_l": 0.08156606851549755,
          "heading_soft_recall": 0.38135277276689356,
          "heading_entity_recall": 0.05555555555555555,
          "article_entity_recall": 0.10334928229665072
        }
      },
      "storm": {
        "success": true,
        "word_count": 2058,
        "metrics": {
          "rouge_1": 0.2843936922240348,
          "rouge_2": 0.06039173014145811,
          "rouge_l": 0.12234910277324633,
          "heading_soft_recall": 0.46583002534779633,
          "heading_entity_recall": 0.16666666666666666,
          "article_entity_recall": 0.11291866028708133
        }
      }
    },
    "Mount_Greylock": {
      "direct": {
        "success": true,
        "word_count": 782,
        "metrics": {
          "rouge_1": 0.1446822101564995,
          "rouge_2": 0.038977635782747606,
          "rouge_l": 0.06164164803577132,
          "heading_soft_recall": 0.3435914397239685,
          "heading_entity_recall": 0.024390243902439025,
          "article_entity_recall": 0.13423959218351741
        }
      },
      "storm": {
        "success": true,
        "word_count": 2307,
        "metrics": {
          "rouge_1": 0.28297668476525073,
          "rouge_2": 0.05463258785942492,
          "rouge_l": 0.10412008942829767,
          "heading_soft_recall": 0.4702566107114156,
          "heading_entity_recall": 0.0975609756097561,
          "article_entity_recall": 0.16737468139337297
        }
      }
    },
    "Music_written_in_all_major_and_or_minor_keys": {
      "direct": {
        "success": true,
        "word_count": 790,
        "metrics": {
          "rouge_1": 0.09225621414913958,
          "rouge_2": 0.01792971551518049,
          "rouge_l": 0.038479923518164434,
          "heading_soft_recall": 0.3136764019727707,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.10966981132075472
        }
      },
      "storm": {
        "success": true,
        "word_count": 1878,
        "metrics": {
          "rouge_1": 0.19455066921606118,
          "rouge_2": 0.038967248386325606,
          "rouge_l": 0.06692160611854685,
          "heading_soft_recall": 0.46400567250592367,
          "heading_entity_recall": 0.11904761904761904,
          "article_entity_recall": 0.1509433962264151
        }
      }
    },
    "Nagpuria_people": {
      "direct": {
        "success": true,
        "word_count": 692,
        "metrics": {
          "rouge_1": 0.09671587827658934,
          "rouge_2": 0.0162748643761302,
          "rouge_l": 0.04850858692377222,
          "heading_soft_recall": 0.39502306545481963,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.08244680851063829
        }
      },
      "storm": {
        "success": true,
        "word_count": 2691,
        "metrics": {
          "rouge_1": 0.28502561012353117,
          "rouge_2": 0.06359252561784208,
          "rouge_l": 0.11449231696294064,
          "heading_soft_recall": 0.5412829641033622,
          "heading_entity_recall": 0.15625,
          "article_entity_recall": 0.1453900709219858
        }
      }
    },
    "O'Sulloc_Tea": {
      "direct": {
        "success": true,
        "word_count": 814,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 1898,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "OceanGate": {
      "direct": {
        "success": true,
        "word_count": 796,
        "metrics": {
          "rouge_1": 0.1796976241900648,
          "rouge_2": 0.033707865168539325,
          "rouge_l": 0.07473002159827213,
          "heading_soft_recall": 0.3974596696595351,
          "heading_entity_recall": 0.037037037037037035,
          "article_entity_recall": 0.17149758454106281
        }
      },
      "storm": {
        "success": true,
        "word_count": 1939,
        "metrics": {
          "rouge_1": 0.3568034557235421,
          "rouge_2": 0.07260155574762317,
          "rouge_l": 0.12526997840172785,
          "heading_soft_recall": 0.4110211158792178,
          "heading_entity_recall": 0.1111111111111111,
          "article_entity_recall": 0.24758454106280192
        }
      }
    },
    "October_2022_United_Kingdom_government_crisis": {
      "direct": {
        "success": true,
        "word_count": 699,
        "metrics": {
          "rouge_1": 0.20106761565836298,
          "rouge_2": 0.05163204747774481,
          "rouge_l": 0.09015421115065243,
          "heading_soft_recall": 0.40645468048751354,
          "heading_entity_recall": 0.058823529411764705,
          "article_entity_recall": 0.16062992125984252
        }
      },
      "storm": {
        "success": true,
        "word_count": 696,
        "metrics": {
          "rouge_1": 0.21352313167259787,
          "rouge_2": 0.057566765578635014,
          "rouge_l": 0.09134045077105575,
          "heading_soft_recall": 0.3260803297162056,
          "heading_entity_recall": 0.058823529411764705,
          "article_entity_recall": 0.16377952755905512
        }
      }
    },
    "Pinoy_Big_Brother:_Kumunity_Season_10": {
      "direct": {
        "success": true,
        "word_count": 889,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 1375,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "Pishdadian_dynasty": {
      "direct": {
        "success": true,
        "word_count": 784,
        "metrics": {
          "rouge_1": 0.14479905437352245,
          "rouge_2": 0.033106710020691696,
          "rouge_l": 0.060874704491725766,
          "heading_soft_recall": 0.3689790517091751,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.1776470588235294
        }
      },
      "storm": {
        "success": true,
        "word_count": 1378,
        "metrics": {
          "rouge_1": 0.21513002364066194,
          "rouge_2": 0.050546851906591785,
          "rouge_l": 0.08717494089834515,
          "heading_soft_recall": 0.5443676799535752,
          "heading_entity_recall": 0.0967741935483871,
          "article_entity_recall": 0.18588235294117647
        }
      }
    },
    "Queue_for_the_lying-in-state_of_Elizabeth_II": {
      "direct": {
        "success": true,
        "word_count": 745,
        "metrics": {
          "rouge_1": 0.16943907156673113,
          "rouge_2": 0.04373065015479876,
          "rouge_l": 0.06963249516441006,
          "heading_soft_recall": 0.40874220728874205,
          "heading_entity_recall": 0.05,
          "article_entity_recall": 0.15541264737406216
        }
      },
      "storm": {
        "success": true,
        "word_count": 691,
        "metrics": {
          "rouge_1": 0.15125725338491297,
          "rouge_2": 0.03908668730650155,
          "rouge_l": 0.0700193423597679,
          "heading_soft_recall": 0.4897366136312485,
          "heading_entity_recall": 0.1,
          "article_entity_recall": 0.12433011789924973
        }
      }
    },
    "Residential_Palace_Darmstadt": {
      "direct": {
        "success": true,
        "word_count": 830,
        "metrics": {
          "rouge_1": 0.20928753180661577,
          "rouge_2": 0.04583068109484405,
          "rouge_l": 0.09923664122137404,
          "heading_soft_recall": 0.4661040592652101,
          "heading_entity_recall": 0.037037037037037035,
          "article_entity_recall": 0.14928057553956833
        }
      },
      "storm": {
        "success": true,
        "word_count": 911,
        "metrics": {
          "rouge_1": 0.18893129770992367,
          "rouge_2": 0.036282622533418206,
          "rouge_l": 0.09414758269720101,
          "heading_soft_recall": 0.36746805333174193,
          "heading_entity_recall": 0.037037037037037035,
          "article_entity_recall": 0.1079136690647482
        }
      }
    },
    "Rock-climbing_equipment": {
      "direct": {
        "success": true,
        "word_count": 764,
        "metrics": {
          "rouge_1": 0.17321288295365278,
          "rouge_2": 0.04007858546168959,
          "rouge_l": 0.06598586017282011,
          "heading_soft_recall": 0.4392003625631332,
          "heading_entity_recall": 0.07142857142857142,
          "article_entity_recall": 0.19021739130434784
        }
      },
      "storm": {
        "success": true,
        "word_count": 2612,
        "metrics": {
          "rouge_1": 0.5278868813825609,
          "rouge_2": 0.14420432220039292,
          "rouge_l": 0.14689709347996857,
          "heading_soft_recall": 0.6699247062206268,
          "heading_entity_recall": 0.30952380952380953,
          "article_entity_recall": 0.37771739130434784
        }
      }
    },
    "Sardar_(2022_film)": {
      "direct": {
        "success": true,
        "word_count": 779,
        "metrics": {
          "rouge_1": 0.12885258076494616,
          "rouge_2": 0.023402674591381872,
          "rouge_l": 0.060898626067582624,
          "heading_soft_recall": 0.5247920109675481,
          "heading_entity_recall": 0.2,
          "article_entity_recall": 0.09857723577235772
        }
      },
      "storm": {
        "success": true,
        "word_count": 1697,
        "metrics": {
          "rouge_1": 0.28852580764946156,
          "rouge_2": 0.0512630014858841,
          "rouge_l": 0.10508726327515781,
          "heading_soft_recall": 0.474877797640287,
          "heading_entity_recall": 0.2,
          "article_entity_recall": 0.18292682926829268
        }
      }
    },
    "Shepherd_Building_Group": {
      "direct": {
        "success": true,
        "word_count": 896,
        "metrics": {
          "rouge_1": 0.24190938511326862,
          "rouge_2": 0.019433198380566803,
          "rouge_l": 0.10032362459546926,
          "heading_soft_recall": 0.33912447032829124,
          "heading_entity_recall": 0.02702702702702703,
          "article_entity_recall": 0.13114754098360656
        }
      },
      "storm": {
        "success": true,
        "word_count": 1374,
        "metrics": {
          "rouge_1": 0.2977346278317152,
          "rouge_2": 0.032388663967611336,
          "rouge_l": 0.1262135922330097,
          "heading_soft_recall": 0.3916081575055917,
          "heading_entity_recall": 0.08108108108108109,
          "article_entity_recall": 0.11657559198542805
        }
      }
    },
    "Silicon_Valley_Bank": {
      "direct": {
        "success": true,
        "word_count": 824,
        "metrics": {
          "rouge_1": 0.14908120924718435,
          "rouge_2": 0.03557663800770827,
          "rouge_l": 0.05838767042086544,
          "heading_soft_recall": 0.4026418961584568,
          "heading_entity_recall": 0.05555555555555555,
          "article_entity_recall": 0.14201183431952663
        }
      },
      "storm": {
        "success": true,
        "word_count": 1824,
        "metrics": {
          "rouge_1": 0.2726733847065797,
          "rouge_2": 0.0791580195671509,
          "rouge_l": 0.1052163604030824,
          "heading_soft_recall": 0.44604919850826263,
          "heading_entity_recall": 0.2777777777777778,
          "article_entity_recall": 0.17159763313609466
        }
      }
    },
    "SpaceX_Starship_Integrated_Flight_Test": {
      "direct": {
        "success": true,
        "word_count": 633,
        "metrics": {
          "rouge_1": 0.11048744460856721,
          "rouge_2": 0.024231678486997636,
          "rouge_l": 0.04697193500738552,
          "heading_soft_recall": 0.48493577043215436,
          "heading_entity_recall": 0.13333333333333333,
          "article_entity_recall": 0.12677388836329234
        }
      },
      "storm": {
        "success": true,
        "word_count": 1983,
        "metrics": {
          "rouge_1": 0.25583456425406204,
          "rouge_2": 0.051418439716312055,
          "rouge_l": 0.09807976366322009,
          "heading_soft_recall": 0.42640285988648735,
          "heading_entity_recall": 0.13333333333333333,
          "article_entity_recall": 0.16745506149479658
        }
      }
    },
    "Speak_Now_(Taylor's_Version)": {
      "direct": {
        "success": true,
        "word_count": 673,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      },
      "storm": {
        "success": true,
        "word_count": 2170,
        "metrics": {
          "rouge_1": 0.0,
          "rouge_2": 0.0,
          "rouge_l": 0.0,
          "heading_soft_recall": 0.0,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.0
        }
      }
    },
    "Storm_Eunice": {
      "direct": {
        "success": true,
        "word_count": 678,
        "metrics": {
          "rouge_1": 0.1106069200226886,
          "rouge_2": 0.02950354609929078,
          "rouge_l": 0.049347702779353374,
          "heading_soft_recall": 0.3113903594868524,
          "heading_entity_recall": 0.05555555555555555,
          "article_entity_recall": 0.10429447852760736
        }
      },
      "storm": {
        "success": true,
        "word_count": 1827,
        "metrics": {
          "rouge_1": 0.20901871809415767,
          "rouge_2": 0.05021276595744681,
          "rouge_l": 0.08252977878615995,
          "heading_soft_recall": 0.38272689070020405,
          "heading_entity_recall": 0.05555555555555555,
          "article_entity_recall": 0.14263803680981596
        }
      }
    },
    "Takeoff_(rapper)": {
      "direct": {
        "success": true,
        "word_count": 1014,
        "metrics": {
          "rouge_1": 0.18719211822660098,
          "rouge_2": 0.04283548142532222,
          "rouge_l": 0.07730200833649109,
          "heading_soft_recall": 0.4437519838412603,
          "heading_entity_recall": 0.13333333333333333,
          "article_entity_recall": 0.15531914893617021
        }
      },
      "storm": {
        "success": true,
        "word_count": 2235,
        "metrics": {
          "rouge_1": 0.33004926108374383,
          "rouge_2": 0.0758150113722517,
          "rouge_l": 0.10875331564986737,
          "heading_soft_recall": 0.42247631748517356,
          "heading_entity_recall": 0.13333333333333333,
          "article_entity_recall": 0.19680851063829788
        }
      }
    },
    "Tartus": {
      "direct": {
        "success": true,
        "word_count": 803,
        "metrics": {
          "rouge_1": 0.1658291457286432,
          "rouge_2": 0.04591152815013405,
          "rouge_l": 0.07035175879396985,
          "heading_soft_recall": 0.39164462972145814,
          "heading_entity_recall": 0.017857142857142856,
          "article_entity_recall": 0.14350590372388738
        }
      },
      "storm": {
        "success": true,
        "word_count": 1992,
        "metrics": {
          "rouge_1": 0.2961474036850921,
          "rouge_2": 0.0690348525469169,
          "rouge_l": 0.11256281407035176,
          "heading_soft_recall": 0.5498893685065783,
          "heading_entity_recall": 0.23214285714285715,
          "article_entity_recall": 0.17620345140781107
        }
      }
    },
    "Taylor_Hawkins": {
      "direct": {
        "success": true,
        "word_count": 945,
        "metrics": {
          "rouge_1": 0.20968342644320298,
          "rouge_2": 0.04918032786885246,
          "rouge_l": 0.07486033519553073,
          "heading_soft_recall": 0.48702435059980914,
          "heading_entity_recall": 0.3888888888888889,
          "article_entity_recall": 0.16681859617137648
        }
      },
      "storm": {
        "success": true,
        "word_count": 1819,
        "metrics": {
          "rouge_1": 0.3217877094972067,
          "rouge_2": 0.0927719821162444,
          "rouge_l": 0.12029795158286778,
          "heading_soft_recall": 0.47907622293992475,
          "heading_entity_recall": 0.1111111111111111,
          "article_entity_recall": 0.17958067456700091
        }
      }
    },
    "The_Book_of_Boba_Fett": {
      "direct": {
        "success": true,
        "word_count": 844,
        "metrics": {
          "rouge_1": 0.1693548387096774,
          "rouge_2": 0.05714285714285714,
          "rouge_l": 0.07526881720430108,
          "heading_soft_recall": 0.526001532562077,
          "heading_entity_recall": 0.21428571428571427,
          "article_entity_recall": 0.14907407407407408
        }
      },
      "storm": {
        "success": true,
        "word_count": 2165,
        "metrics": {
          "rouge_1": 0.3581989247311828,
          "rouge_2": 0.1226890756302521,
          "rouge_l": 0.1381048387096774,
          "heading_soft_recall": 0.5772785358130932,
          "heading_entity_recall": 0.39285714285714285,
          "article_entity_recall": 0.19444444444444445
        }
      }
    },
    "The_Northman": {
      "direct": {
        "success": true,
        "word_count": 847,
        "metrics": {
          "rouge_1": 0.1384853168469861,
          "rouge_2": 0.029684601113172542,
          "rouge_l": 0.06306027820710974,
          "heading_soft_recall": 0.5023171920329332,
          "heading_entity_recall": 0.12,
          "article_entity_recall": 0.1006006006006006
        }
      },
      "storm": {
        "success": true,
        "word_count": 2733,
        "metrics": {
          "rouge_1": 0.3381761978361669,
          "rouge_2": 0.06740878169449598,
          "rouge_l": 0.1261205564142195,
          "heading_soft_recall": 0.5026506166905165,
          "heading_entity_recall": 0.16,
          "article_entity_recall": 0.1704204204204204
        }
      }
    },
    "The_Papers_of_Benjamin_Franklin": {
      "direct": {
        "success": true,
        "word_count": 763,
        "metrics": {
          "rouge_1": 0.1844391785150079,
          "rouge_2": 0.04820229158435401,
          "rouge_l": 0.07622432859399685,
          "heading_soft_recall": 0.3774489292076656,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.20055710306406685
        }
      },
      "storm": {
        "success": true,
        "word_count": 1368,
        "metrics": {
          "rouge_1": 0.31516587677725116,
          "rouge_2": 0.10391149743184512,
          "rouge_l": 0.12243285939968404,
          "heading_soft_recall": 0.29621729467596325,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.2562674094707521
        }
      }
    },
    "Those_Once_Loyal": {
      "direct": {
        "success": true,
        "word_count": 964,
        "metrics": {
          "rouge_1": 0.11021920345785736,
          "rouge_2": 0.01173563928350834,
          "rouge_l": 0.05464649583204693,
          "heading_soft_recall": 0.4099895348151525,
          "heading_entity_recall": 0.034482758620689655,
          "article_entity_recall": 0.09386973180076628
        }
      },
      "storm": {
        "success": true,
        "word_count": 1861,
        "metrics": {
          "rouge_1": 0.293300401358444,
          "rouge_2": 0.08060531192093885,
          "rouge_l": 0.11299783883914788,
          "heading_soft_recall": 0.3827974796295166,
          "heading_entity_recall": 0.034482758620689655,
          "article_entity_recall": 0.15996168582375478
        }
      }
    },
    "Threads_(social_network)": {
      "direct": {
        "success": true,
        "word_count": 1159,
        "metrics": {
          "rouge_1": 0.2583143507972665,
          "rouge_2": 0.05332725615314494,
          "rouge_l": 0.08656036446469248,
          "heading_soft_recall": 0.3720740079879761,
          "heading_entity_recall": 0.02702702702702703,
          "article_entity_recall": 0.21151439299123906
        }
      },
      "storm": {
        "success": true,
        "word_count": 1616,
        "metrics": {
          "rouge_1": 0.37312072892938497,
          "rouge_2": 0.10437556973564266,
          "rouge_l": 0.12072892938496584,
          "heading_soft_recall": 0.3652922948822379,
          "heading_entity_recall": 0.10810810810810811,
          "article_entity_recall": 0.24405506883604505
        }
      }
    },
    "Top-four_primary": {
      "direct": {
        "success": true,
        "word_count": 822,
        "metrics": {
          "rouge_1": 0.18636003172085647,
          "rouge_2": 0.013492063492063493,
          "rouge_l": 0.0753370340999207,
          "heading_soft_recall": 0.3647303730249405,
          "heading_entity_recall": 0.06666666666666667,
          "article_entity_recall": 0.1172962226640159
        }
      },
      "storm": {
        "success": true,
        "word_count": 1110,
        "metrics": {
          "rouge_1": 0.23790642347343377,
          "rouge_2": 0.027777777777777776,
          "rouge_l": 0.09674861221252974,
          "heading_soft_recall": 0.3632404744625092,
          "heading_entity_recall": 0.06666666666666667,
          "article_entity_recall": 0.11133200795228629
        }
      }
    },
    "Treat_Williams": {
      "direct": {
        "success": true,
        "word_count": 763,
        "metrics": {
          "rouge_1": 0.15939479239971852,
          "rouge_2": 0.037310806054206266,
          "rouge_l": 0.06685432793807178,
          "heading_soft_recall": 0.5509705781936646,
          "heading_entity_recall": 0.21212121212121213,
          "article_entity_recall": 0.11705685618729098
        }
      },
      "storm": {
        "success": true,
        "word_count": 587,
        "metrics": {
          "rouge_1": 0.10802251935256861,
          "rouge_2": 0.023231256599788808,
          "rouge_l": 0.04926108374384237,
          "heading_soft_recall": 0.39650885164737704,
          "heading_entity_recall": 0.06060606060606061,
          "article_entity_recall": 0.06688963210702341
        }
      }
    },
    "Typhoon_Hinnamnor": {
      "direct": {
        "success": true,
        "word_count": 752,
        "metrics": {
          "rouge_1": 0.14556296036478428,
          "rouge_2": 0.041403508771929824,
          "rouge_l": 0.06383725008768854,
          "heading_soft_recall": 0.40928807482123375,
          "heading_entity_recall": 0.08333333333333333,
          "article_entity_recall": 0.20328849028400597
        }
      },
      "storm": {
        "success": true,
        "word_count": 1842,
        "metrics": {
          "rouge_1": 0.2777972641178534,
          "rouge_2": 0.07473684210526316,
          "rouge_l": 0.11539810592774465,
          "heading_soft_recall": 0.521457701921463,
          "heading_entity_recall": 0.5,
          "article_entity_recall": 0.24813153961136025
        }
      }
    },
    "Vande_Bharat_Express": {
      "direct": {
        "success": true,
        "word_count": 940,
        "metrics": {
          "rouge_1": 0.24285021812893845,
          "rouge_2": 0.06401551891367604,
          "rouge_l": 0.08822103732428502,
          "heading_soft_recall": 0.4251420311629772,
          "heading_entity_recall": 0.06896551724137931,
          "article_entity_recall": 0.20565552699228792
        }
      },
      "storm": {
        "success": true,
        "word_count": 1557,
        "metrics": {
          "rouge_1": 0.31943771206980126,
          "rouge_2": 0.08535402521823472,
          "rouge_l": 0.11682016480853126,
          "heading_soft_recall": 0.3024229680498441,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.2069408740359897
        }
      }
    },
    "Zillennials": {
      "direct": {
        "success": true,
        "word_count": 764,
        "metrics": {
          "rouge_1": 0.2490272373540856,
          "rouge_2": 0.04931862426995458,
          "rouge_l": 0.0933852140077821,
          "heading_soft_recall": 0.3126763092974822,
          "heading_entity_recall": 0.0,
          "article_entity_recall": 0.18944099378881987
        }
      },
      "storm": {
        "success": true,
        "word_count": 693,
        "metrics": {
          "rouge_1": 0.24059662775616084,
          "rouge_2": 0.04737183646982479,
          "rouge_l": 0.0907911802853437,
          "heading_soft_recall": 0.40562302246689796,
          "heading_entity_recall": 0.037037037037037035,
          "article_entity_recall": 0.17236024844720496
        }
      }
    }
  },
  "summary": {
    "total_topics": 100,
    "total_articles": 200,
    "successful_evaluations": 200,
    "methods_run": ["direct", "storm"]
  }
}
